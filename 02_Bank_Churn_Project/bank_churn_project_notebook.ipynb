{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello James!\n",
    "\n",
    "My name is Dmitry.  I'm glad to review your work today.\n",
    "I will mark your mistakes and give you some hints how it is possible to fix them. We are getting ready for real job, where your team leader/senior colleague will do exactly the same. Don't worry and study with pleasure! \n",
    "\n",
    "Below you will find my comments - **please do not move, modify or delete them**.\n",
    "\n",
    "You can find my comments in green, yellow or red boxes like this:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Success. Everything is done succesfully.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Remarks. Some recommendations.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Needs fixing. The block requires some corrections. Work can't be accepted with the red comments.\n",
    "</div>\n",
    "\n",
    "You can answer me by using this:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Student answer.</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Text here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "- In this project, I create a classification model that predicts whether a customer will leave Beta Bank.\n",
    "- The dataset 'Churn.csv' includes 13 features. These are used to train a classification model that predicts whether the target ('Exited') is true or false. Of the included features, 10 are used to train the models. Both categorical and numerical features are used. Categorical features are encoded while numerical features are scaled.\n",
    "- There is a class imbalance for the target feature. About 80% of the dataset contains false (0) target values, meaning that most of the customers in the sample did not leave the bank.\n",
    "- I train 4 models (Logistic Regression, Decision Tree, Random Forest and Gradient Boosting) and select the most optimized model through hyperparameter tuning and up/downsampling.\n",
    "- The threshold for the model f1 value is set at 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Great start with an introduction!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load and Prepare Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries/Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('Churn.csv')\n",
    "except FileNotFoundError:\n",
    "    df =  pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several of the rows pertaining to personal info (Surname, CustomerId) can be eliminated since they are not useful in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly 1/10th of values in the Tenure column are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "NaN     909\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range is from 0.0 to 10.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a banking context, tenure is the period (years) for the maturation of a fixed deposit. It is possible that some customers have made no fixed deposit. Missing values may indicate that the customer does not have a product that involves tenure. Therefore, I replace missing values with '0.0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9945</td>\n",
       "      <td>15703923</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>744</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190409.34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138361.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>9957</td>\n",
       "      <td>15707861</td>\n",
       "      <td>Nucci</td>\n",
       "      <td>520</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85216.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117369.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>9965</td>\n",
       "      <td>15642785</td>\n",
       "      <td>Douglas</td>\n",
       "      <td>479</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117593.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113308.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>15586914</td>\n",
       "      <td>Nepean</td>\n",
       "      <td>659</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123841.49</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96833.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "30           31    15589475    Azikiwe          591     Spain  Female   39   \n",
       "48           49    15766205        Yin          550   Germany    Male   38   \n",
       "51           52    15768193  Trevisani          585   Germany    Male   36   \n",
       "53           54    15702298   Parkhill          655   Germany    Male   41   \n",
       "60           61    15651280     Hunter          742   Germany    Male   35   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9944       9945    15703923    Cameron          744   Germany    Male   41   \n",
       "9956       9957    15707861      Nucci          520    France  Female   46   \n",
       "9964       9965    15642785    Douglas          479    France    Male   34   \n",
       "9985       9986    15586914     Nepean          659    France    Male   36   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "30       NaN       0.00              3          1               0   \n",
       "48       NaN  103391.38              1          0               1   \n",
       "51       NaN  146050.97              2          0               0   \n",
       "53       NaN  125561.97              1          0               0   \n",
       "60       NaN  136857.00              1          0               0   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9944     NaN  190409.34              2          1               1   \n",
       "9956     NaN   85216.61              1          1               0   \n",
       "9964     NaN  117593.48              2          0               0   \n",
       "9985     NaN  123841.49              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "30          140469.38       1  \n",
       "48           90878.13       0  \n",
       "51           86424.57       0  \n",
       "53          164040.94       1  \n",
       "60           84509.57       0  \n",
       "...               ...     ...  \n",
       "9944        138361.48       0  \n",
       "9956        117369.52       1  \n",
       "9964        113308.29       0  \n",
       "9985         96833.00       0  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[909 rows x 14 columns]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Tenure'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure'].fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Correct.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CustomerId'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates of the unique 'CustomerId' column. We can be reasonably sure that no accounts were duplicated in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminate unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the following columns contain personal data not relevant to the classification task, they are removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['RowNumber','CustomerId','Surname',]\n",
    "df.drop(cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Great preprocessing!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate data into target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('Exited',axis=1)\n",
    "target = df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate data into train, valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features,target,test_size=0.2,random_state=12345)\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train,target_train,test_size=0.25,random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is separated into the train, validation and test sets by a 3:1:1 ratio. Leaving us with a train set of 6000 rows, and validation and test sets of 2000 rows each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27/1037083430.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_test[numeric] = scaler.transform(features_test[numeric])\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "numeric = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling gives the numeric features equal weight and increases the models ability to identify the most important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Good preparation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_features_train = pd.get_dummies(features_train,drop_first=True)\n",
    "ohe_features_valid = pd.get_dummies(features_valid,drop_first=True)\n",
    "ohe_features_test = pd.get_dummies(features_test,drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistic regression model, I encode categorical features with one hot encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=12345, solver='liblinear')"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr_model = LogisticRegression(solver='liblinear',random_state=12345)\n",
    "logr_model.fit(ohe_features_train,target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_valid = logr_model.predict(ohe_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1551,   58],\n",
       "       [ 310,   81]])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(target_valid,predicted_valid)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3056603773584906"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(target_valid,predicted_valid)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "encode_features_train = pd.DataFrame(encoder.fit_transform(features_train),columns=features_train.columns)\n",
    "encode_features_valid = pd.DataFrame(encoder.fit_transform(features_valid),columns=features_valid.columns)\n",
    "encode_features_test = pd.DataFrame(encoder.fit_transform(features_test),columns=features_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next 3 models (since they are tree models) I encode categorical features with the OrdinalEncoder object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:2 f1:0.5037037037037037\n",
      "depth:3 f1:0.39382239382239387\n",
      "depth:4 f1:0.42585551330798477\n",
      "depth:5 f1:0.5150501672240801\n",
      "depth:6 f1:0.4888123924268503\n",
      "depth:7 f1:0.5074135090609555\n",
      "depth:8 f1:0.5298621745788668\n",
      "depth:9 f1:0.496124031007752\n",
      "best_model:DecisionTreeClassifier(max_depth=8, random_state=12345) best_score:0.5298621745788668\n"
     ]
    }
   ],
   "source": [
    "best_tree_model = None\n",
    "best_tree_score = 0\n",
    "for depth in range(2,10):\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth,random_state=12345)\n",
    "    tree_model.fit(encode_features_train,target_train)\n",
    "    predicted_valid = tree_model.predict(encode_features_valid)\n",
    "    f1 = f1_score(target_valid,predicted_valid)\n",
    "    print(f'depth:{depth} f1:{f1}')\n",
    "    if f1 > best_tree_score:\n",
    "        best_tree_model = tree_model\n",
    "        best_tree_score = f1\n",
    "print(f'best_model:{best_tree_model} best_score:{best_tree_score}')\n",
    "tree_model = best_tree_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best max depth of the tree in a range of 2-9 is 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_valid = tree_model.predict(encode_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1520,   89],\n",
       "       [ 218,  173]])"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(target_valid,predicted_valid)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5298621745788668"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(target_valid,predicted_valid)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:2,n_est:10 f1:0.11031175059952038\n",
      "depth:2,n_est:20 f1:0.18433179723502302\n",
      "depth:2,n_est:30 f1:0.17633410672853828\n",
      "depth:2,n_est:40 f1:0.18433179723502302\n",
      "depth:2,n_est:50 f1:0.1639344262295082\n",
      "depth:2,n_est:60 f1:0.15925058548009366\n",
      "depth:2,n_est:70 f1:0.16744186046511628\n",
      "depth:2,n_est:80 f1:0.16744186046511628\n",
      "depth:2,n_est:90 f1:0.16783216783216784\n",
      "depth:3,n_est:10 f1:0.2331838565022422\n",
      "depth:3,n_est:20 f1:0.24833702882483366\n",
      "depth:3,n_est:30 f1:0.2560706401766004\n",
      "depth:3,n_est:40 f1:0.22171945701357468\n",
      "depth:3,n_est:50 f1:0.22171945701357468\n",
      "depth:3,n_est:60 f1:0.23024830699774265\n",
      "depth:3,n_est:70 f1:0.21818181818181817\n",
      "depth:3,n_est:80 f1:0.2222222222222222\n",
      "depth:3,n_est:90 f1:0.21004566210045664\n",
      "depth:4,n_est:10 f1:0.45735027223230484\n",
      "depth:4,n_est:20 f1:0.43856332703213613\n",
      "depth:4,n_est:30 f1:0.4364326375711575\n",
      "depth:4,n_est:40 f1:0.47723132969034604\n",
      "depth:4,n_est:50 f1:0.4725274725274725\n",
      "depth:4,n_est:60 f1:0.45555555555555555\n",
      "depth:4,n_est:70 f1:0.43129770992366406\n",
      "depth:4,n_est:80 f1:0.42389210019267826\n",
      "depth:4,n_est:90 f1:0.40313111545988256\n",
      "depth:5,n_est:10 f1:0.4795737122557726\n",
      "depth:5,n_est:20 f1:0.4781021897810218\n",
      "depth:5,n_est:30 f1:0.4705882352941177\n",
      "depth:5,n_est:40 f1:0.4854014598540146\n",
      "depth:5,n_est:50 f1:0.48275862068965525\n",
      "depth:5,n_est:60 f1:0.48628884826325414\n",
      "depth:5,n_est:70 f1:0.4844036697247706\n",
      "depth:5,n_est:80 f1:0.4781021897810218\n",
      "depth:5,n_est:90 f1:0.47426470588235303\n",
      "depth:6,n_est:10 f1:0.4820143884892087\n",
      "depth:6,n_est:20 f1:0.4753199268738574\n",
      "depth:6,n_est:30 f1:0.4658040665434381\n",
      "depth:6,n_est:40 f1:0.4746376811594203\n",
      "depth:6,n_est:50 f1:0.4836363636363637\n",
      "depth:6,n_est:60 f1:0.49731663685152055\n",
      "depth:6,n_est:70 f1:0.4828828828828829\n",
      "depth:6,n_est:80 f1:0.4828828828828829\n",
      "depth:6,n_est:90 f1:0.48648648648648646\n",
      "depth:7,n_est:10 f1:0.48056537102473496\n",
      "depth:7,n_est:20 f1:0.4937388193202147\n",
      "depth:7,n_est:30 f1:0.48841354723707664\n",
      "depth:7,n_est:40 f1:0.4820143884892087\n",
      "depth:7,n_est:50 f1:0.48300536672629696\n",
      "depth:7,n_est:60 f1:0.4839857651245551\n",
      "depth:7,n_est:70 f1:0.4865831842576029\n",
      "depth:7,n_est:80 f1:0.48928571428571427\n",
      "depth:7,n_est:90 f1:0.48484848484848486\n",
      "depth:8,n_est:10 f1:0.4676258992805756\n",
      "depth:8,n_est:20 f1:0.472072072072072\n",
      "depth:8,n_est:30 f1:0.4693140794223827\n",
      "depth:8,n_est:40 f1:0.47058823529411764\n",
      "depth:8,n_est:50 f1:0.47349823321554774\n",
      "depth:8,n_est:60 f1:0.48056537102473496\n",
      "depth:8,n_est:70 f1:0.4787234042553191\n",
      "depth:8,n_est:80 f1:0.47787610619469034\n",
      "depth:8,n_est:90 f1:0.4743362831858407\n",
      "depth:9,n_est:10 f1:0.4853700516351118\n",
      "depth:9,n_est:20 f1:0.49116607773851595\n",
      "depth:9,n_est:30 f1:0.48516579406631766\n",
      "depth:9,n_est:40 f1:0.5077720207253885\n",
      "depth:9,n_est:50 f1:0.5085910652920963\n",
      "depth:9,n_est:60 f1:0.515358361774744\n",
      "depth:9,n_est:70 f1:0.5094664371772806\n",
      "depth:9,n_est:80 f1:0.5094664371772806\n",
      "depth:9,n_est:90 f1:0.5085910652920963\n",
      "depth:10,n_est:10 f1:0.49128919860627174\n",
      "depth:10,n_est:20 f1:0.5025996533795494\n",
      "depth:10,n_est:30 f1:0.5138888888888888\n",
      "depth:10,n_est:40 f1:0.4946996466431095\n",
      "depth:10,n_est:50 f1:0.4903677758318739\n",
      "depth:10,n_est:60 f1:0.48951048951048953\n",
      "depth:10,n_est:70 f1:0.49740932642487057\n",
      "depth:10,n_est:80 f1:0.49484536082474223\n",
      "depth:10,n_est:90 f1:0.4965277777777778\n",
      "depth:11,n_est:10 f1:0.5\n",
      "depth:11,n_est:20 f1:0.5068027210884354\n",
      "depth:11,n_est:30 f1:0.49480968858131485\n",
      "depth:11,n_est:40 f1:0.5094664371772806\n",
      "depth:11,n_est:50 f1:0.5102739726027398\n",
      "depth:11,n_est:60 f1:0.5077186963979418\n",
      "depth:11,n_est:70 f1:0.5145797598627787\n",
      "depth:11,n_est:80 f1:0.5162393162393163\n",
      "depth:11,n_est:90 f1:0.5094017094017094\n",
      "depth:12,n_est:10 f1:0.5075630252100839\n",
      "depth:12,n_est:20 f1:0.503448275862069\n",
      "depth:12,n_est:30 f1:0.5060240963855422\n",
      "depth:12,n_est:40 f1:0.5094664371772806\n",
      "depth:12,n_est:50 f1:0.5103448275862068\n",
      "depth:12,n_est:60 f1:0.5214408233276158\n",
      "depth:12,n_est:70 f1:0.5197934595524957\n",
      "depth:12,n_est:80 f1:0.5172413793103449\n",
      "depth:12,n_est:90 f1:0.5103448275862068\n",
      "depth:13,n_est:10 f1:0.5131578947368421\n",
      "depth:13,n_est:20 f1:0.5017064846416383\n",
      "depth:13,n_est:30 f1:0.5085324232081911\n",
      "depth:13,n_est:40 f1:0.506896551724138\n",
      "depth:13,n_est:50 f1:0.5043177892918824\n",
      "depth:13,n_est:60 f1:0.5103448275862068\n",
      "depth:13,n_est:70 f1:0.5120274914089347\n",
      "depth:13,n_est:80 f1:0.5\n",
      "depth:13,n_est:90 f1:0.506896551724138\n",
      "depth:14,n_est:10 f1:0.5032467532467532\n",
      "depth:14,n_est:20 f1:0.4940374787052811\n",
      "depth:14,n_est:30 f1:0.5102040816326531\n",
      "depth:14,n_est:40 f1:0.5087108013937282\n",
      "depth:14,n_est:50 f1:0.5043478260869565\n",
      "depth:14,n_est:60 f1:0.5069444444444445\n",
      "depth:14,n_est:70 f1:0.5214408233276158\n",
      "depth:14,n_est:80 f1:0.5060658578856152\n",
      "depth:14,n_est:90 f1:0.5086505190311419\n",
      "best_model:RandomForestClassifier(max_depth=12, n_estimators=60, random_state=12345) best_score:0.5214408233276158\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_score = 0\n",
    "for depth in range(2,15):\n",
    "    for est in range(10,100,10):\n",
    "        forest_model = RandomForestClassifier(n_estimators=est,max_depth=depth,random_state=12345)\n",
    "        forest_model.fit(encode_features_train,target_train)\n",
    "        predicted_valid = forest_model.predict(encode_features_valid)\n",
    "        f1 = f1_score(target_valid,predicted_valid)\n",
    "        print(f'depth:{depth},n_est:{est} f1:{f1}')\n",
    "        if f1 > best_forest_score:\n",
    "            best_forest_model = forest_model\n",
    "            best_forest_score = f1\n",
    "print(f'best_model:{best_forest_model} best_score:{best_forest_score}')\n",
    "forest_model = best_forest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model had a max depth of 12 and 60 estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_valid = forest_model.predict(encode_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1569,   40],\n",
       "       [ 239,  152]])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(target_valid,predicted_valid)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5214408233276158"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(target_valid,predicted_valid)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clear improvement over the last 2 models, but still below the desired threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth:2,n_est:10 f1:0.2027027027027027\n",
      "depth:2,n_est:20 f1:0.493006993006993\n",
      "depth:2,n_est:30 f1:0.5060240963855422\n",
      "depth:2,n_est:40 f1:0.5144804088586031\n",
      "depth:2,n_est:50 f1:0.528428093645485\n",
      "depth:2,n_est:60 f1:0.5275459098497496\n",
      "depth:2,n_est:70 f1:0.5266666666666667\n",
      "depth:2,n_est:80 f1:0.5306799336650083\n",
      "depth:2,n_est:90 f1:0.5322314049586776\n",
      "depth:3,n_est:10 f1:0.403960396039604\n",
      "depth:3,n_est:20 f1:0.49016100178890876\n",
      "depth:3,n_est:30 f1:0.5174825174825175\n",
      "depth:3,n_est:40 f1:0.5078809106830122\n",
      "depth:3,n_est:50 f1:0.5172413793103449\n",
      "depth:3,n_est:60 f1:0.5144804088586031\n",
      "depth:3,n_est:70 f1:0.5195246179966045\n",
      "depth:3,n_est:80 f1:0.5211505922165821\n",
      "depth:3,n_est:90 f1:0.5211505922165821\n",
      "depth:4,n_est:10 f1:0.45283018867924535\n",
      "depth:4,n_est:20 f1:0.5\n",
      "depth:4,n_est:30 f1:0.517361111111111\n",
      "depth:4,n_est:40 f1:0.5103448275862068\n",
      "depth:4,n_est:50 f1:0.5077720207253885\n",
      "depth:4,n_est:60 f1:0.5121107266435986\n",
      "depth:4,n_est:70 f1:0.5172413793103449\n",
      "depth:4,n_est:80 f1:0.5180102915951973\n",
      "depth:4,n_est:90 f1:0.5196581196581197\n",
      "depth:5,n_est:10 f1:0.4523364485981308\n",
      "depth:5,n_est:20 f1:0.49295774647887325\n",
      "depth:5,n_est:30 f1:0.5104166666666666\n",
      "depth:5,n_est:40 f1:0.5145797598627787\n",
      "depth:5,n_est:50 f1:0.5172413793103449\n",
      "depth:5,n_est:60 f1:0.5297113752122241\n",
      "depth:5,n_est:70 f1:0.5186440677966102\n",
      "depth:5,n_est:80 f1:0.5177664974619289\n",
      "depth:5,n_est:90 f1:0.5186440677966102\n",
      "depth:6,n_est:10 f1:0.45387453874538736\n",
      "depth:6,n_est:20 f1:0.49295774647887325\n",
      "depth:6,n_est:30 f1:0.5129087779690189\n",
      "depth:6,n_est:40 f1:0.5196581196581197\n",
      "depth:6,n_est:50 f1:0.5177664974619289\n",
      "depth:6,n_est:60 f1:0.5109983079526227\n",
      "depth:6,n_est:70 f1:0.5109983079526227\n",
      "depth:6,n_est:80 f1:0.5050505050505051\n",
      "depth:6,n_est:90 f1:0.509212730318258\n",
      "depth:7,n_est:10 f1:0.4419475655430712\n",
      "depth:7,n_est:20 f1:0.48686514886164634\n",
      "depth:7,n_est:30 f1:0.5076142131979696\n",
      "depth:7,n_est:40 f1:0.49152542372881364\n",
      "depth:7,n_est:50 f1:0.49069373942470396\n",
      "depth:7,n_est:60 f1:0.49324324324324326\n",
      "depth:7,n_est:70 f1:0.4916943521594685\n",
      "depth:7,n_est:80 f1:0.48595041322314053\n",
      "depth:7,n_est:90 f1:0.4858569051580699\n",
      "depth:8,n_est:10 f1:0.4543828264758497\n",
      "depth:8,n_est:20 f1:0.4839255499153976\n",
      "depth:8,n_est:30 f1:0.49328859060402686\n",
      "depth:8,n_est:40 f1:0.4892561983471075\n",
      "depth:8,n_est:50 f1:0.48013245033112584\n",
      "depth:8,n_est:60 f1:0.49427168576104746\n",
      "depth:8,n_est:70 f1:0.49837133550488605\n",
      "depth:8,n_est:80 f1:0.49756097560975604\n",
      "depth:8,n_est:90 f1:0.4975767366720517\n",
      "depth:9,n_est:10 f1:0.43478260869565216\n",
      "depth:9,n_est:20 f1:0.4888888888888889\n",
      "depth:9,n_est:30 f1:0.48918469217970045\n",
      "depth:9,n_est:40 f1:0.48092868988391374\n",
      "depth:9,n_est:50 f1:0.4917491749174917\n",
      "depth:9,n_est:60 f1:0.49508196721311476\n",
      "depth:9,n_est:70 f1:0.4918032786885245\n",
      "depth:9,n_est:80 f1:0.49099836333878877\n",
      "depth:9,n_est:90 f1:0.4901960784313726\n",
      "best_model:GradientBoostingClassifier(max_depth=2, n_estimators=90, random_state=12345) best_score:0.5322314049586776\n"
     ]
    }
   ],
   "source": [
    "best_boost_model = None\n",
    "best_boost_score = 0\n",
    "for depth in range(2,10):\n",
    "    for est in range(10,100,10):\n",
    "        boost_model = GradientBoostingClassifier(n_estimators=est,max_depth=depth,random_state=12345)\n",
    "        boost_model.fit(encode_features_train,target_train)\n",
    "        predicted_valid = boost_model.predict(encode_features_valid)\n",
    "        f1 = f1_score(target_valid,predicted_valid)\n",
    "        print(f'depth:{depth},n_est:{est} f1:{f1}')\n",
    "        if f1 > best_boost_score:\n",
    "            best_boost_model = boost_model\n",
    "            best_boost_score = f1\n",
    "print(f'best_model:{best_boost_model} best_score:{best_boost_score}')\n",
    "boost_model = best_boost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_valid = boost_model.predict(encode_features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1556,   53],\n",
       "       [ 230,  161]])"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(target_valid,predicted_valid)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5322314049586776"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(target_valid,predicted_valid)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Well done!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve Model Quality:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.796833\n",
       "1    0.203167\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly 80% of customers did not leave the bank. This is a significant imbalance and reduces the effectiveness of the machine learning models. It is easy for the model to 'cheat' if it predicts '0' for all cases. This results in high accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_valid = pd.Series(data=0,index=target_valid.index)\n",
    "accuracy = accuracy_score(target_valid,constant_valid)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But '0' for the f1 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(target_valid,constant_valid)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I find ways to reduce the class imbalance and make the models more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsample/Downsample and Class Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features,target,repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled,target_upsampled,random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function increases the number of training rows with '1' answers and shuffles them back in with training rows with '0' answers. This helps the model to encounter more rows with the lesser class weight so it can learn how to identify them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features,target,frac):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=frac,random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=frac,random_state=12345)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled,target_downsampled,random_state=12345)\n",
    "\n",
    "    return features_downsampled,target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function decreases the number of rows with a '0' answer (the overrepresented class) and shuffles them in with the '1' rows. This improves the class balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downsampling training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac:0.0 score:0.32705980761187786\n",
      "frac:0.05 score:0.3779214321233217\n",
      "frac:0.1 score:0.46306068601583117\n",
      "frac:0.15000000000000002 score:0.5026495079485238\n",
      "frac:0.2 score:0.5303964757709251\n",
      "frac:0.25 score:0.543859649122807\n",
      "frac:0.30000000000000004 score:0.5622317596566523\n",
      "frac:0.35000000000000003 score:0.5609756097560975\n",
      "frac:0.4 score:0.5561993047508691\n",
      "frac:0.45 score:0.5544554455445545\n",
      "frac:0.5 score:0.5535714285714285\n",
      "frac:0.55 score:0.5608465608465608\n",
      "Best model:RandomForestClassifier(class_weight='balanced', max_depth=12, n_estimators=60,\n",
      "                       random_state=12345) score:0.5622317596566523 frac:0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_score = 0\n",
    "best_frac = None\n",
    "for frac in np.arange(0,0.6,0.05):\n",
    "    features_downsampled,target_downsampled = downsample(features_train,target_train,frac)\n",
    "    encoder = OrdinalEncoder()\n",
    "    enc_features_downsampled = pd.DataFrame(encoder.fit_transform(features_downsampled),columns=features_downsampled.columns)\n",
    "    forest_model = RandomForestClassifier(class_weight='balanced',n_estimators=60,max_depth=12,random_state=12345)\n",
    "    forest_model.fit(enc_features_downsampled,target_downsampled)\n",
    "    predicted_valid = forest_model.predict(encode_features_valid)\n",
    "    f1 = f1_score(target_valid,predicted_valid)\n",
    "    if f1 > best_forest_score:\n",
    "        best_forest_model = forest_model\n",
    "        best_forest_score = f1\n",
    "        best_frac = frac\n",
    "    print(f'frac:{frac} score:{f1}')\n",
    "print(f'Best model:{best_forest_model} score:{best_forest_score} frac:{best_frac}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.683294\n",
       "1    0.316706\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_downsampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upsampling training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat:1 score:0.5278219395866454\n",
      "repeat:2 score:0.539454806312769\n",
      "repeat:3 score:0.5495118549511855\n",
      "repeat:4 score:0.5553997194950913\n",
      "repeat:5 score:0.5527777777777777\n",
      "Best model:RandomForestClassifier(class_weight='balanced', max_depth=12, n_estimators=60,\n",
      "                       random_state=12345) score:0.5553997194950913 repeat:4\n"
     ]
    }
   ],
   "source": [
    "best_forest_model = None\n",
    "best_forest_score = 0\n",
    "best_repeat = None\n",
    "for repeat in range(1,6):\n",
    "    features_upsampled,target_upsampled = upsample(features_train,target_train,repeat)\n",
    "    encoder = OrdinalEncoder()\n",
    "    enc_features_upsampled = pd.DataFrame(encoder.fit_transform(features_upsampled),columns=features_upsampled.columns)\n",
    "    forest_model = RandomForestClassifier(class_weight='balanced',n_estimators=60,max_depth=12,random_state=12345)\n",
    "    forest_model.fit(enc_features_upsampled,target_upsampled)\n",
    "    predicted_valid = forest_model.predict(encode_features_valid)\n",
    "    f1 = f1_score(target_valid,predicted_valid)\n",
    "    if f1 > best_forest_score:\n",
    "        best_forest_model = forest_model\n",
    "        best_forest_score = f1\n",
    "        best_repeat = repeat\n",
    "    print(f'repeat:{repeat} score:{f1}')\n",
    "print(f'Best model:{best_forest_model} score:{best_forest_score} repeat:{best_repeat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.560408\n",
       "0    0.439592\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_upsampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since downsampling at a fraction of 0.3 produced the best result. I will use the downsampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled,target_downsampled = downsample(features_train,target_train,best_frac)\n",
    "encoder = OrdinalEncoder()\n",
    "enc_features_downsampled = pd.DataFrame(encoder.fit_transform(features_downsampled),columns=features_downsampled.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>536.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>387.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>266.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>286.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>248.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2179.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2653 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender   Age  Tenure  Balance  NumOfProducts  \\\n",
       "0           119.0        2.0     0.0  15.0     7.0   1325.0            0.0   \n",
       "1           279.0        0.0     1.0  45.0     7.0   1530.0            0.0   \n",
       "2           181.0        1.0     1.0  18.0     0.0   1159.0            1.0   \n",
       "3           155.0        0.0     0.0  18.0     1.0      0.0            0.0   \n",
       "4           387.0        1.0     1.0  12.0     8.0   1713.0            0.0   \n",
       "...           ...        ...     ...   ...     ...      ...            ...   \n",
       "2648        266.0        2.0     0.0  20.0     3.0   1286.0            2.0   \n",
       "2649        286.0        1.0     0.0  17.0     3.0   1610.0            1.0   \n",
       "2650        248.0        0.0     0.0  18.0     8.0      0.0            0.0   \n",
       "2651        149.0        0.0     0.0  23.0     9.0   1361.0            0.0   \n",
       "2652        221.0        0.0     0.0  17.0     8.0      0.0            0.0   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0           1.0             0.0            833.0  \n",
       "1           0.0             0.0           1580.0  \n",
       "2           1.0             1.0            536.0  \n",
       "3           1.0             1.0            741.0  \n",
       "4           1.0             0.0           1104.0  \n",
       "...         ...             ...              ...  \n",
       "2648        1.0             0.0             48.0  \n",
       "2649        1.0             1.0            534.0  \n",
       "2650        0.0             1.0           2108.0  \n",
       "2651        1.0             0.0           1879.0  \n",
       "2652        0.0             0.0           2179.0  \n",
       "\n",
       "[2653 rows x 10 columns]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "enc_features_downsampled = pd.DataFrame(encoder.fit_transform(features_downsampled),columns=features_downsampled.columns)\n",
    "enc_features_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Gradient Boosting Classifier model performed well in the previous section, I train it with the downsampled training set. The hyperparamters are set to the specifications of the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5933333333333334"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_model = GradientBoostingClassifier(max_depth=2,n_estimators=90,random_state=12345)\n",
    "boost_model.fit(enc_features_downsampled,target_downsampled)\n",
    "predicted_valid = boost_model.predict(encode_features_valid)\n",
    "f1 = f1_score(target_valid,predicted_valid)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Excellent!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we meet the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_valid = boost_model.predict_proba(encode_features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:0.0 precision: 0.1955 recall: 1.0 f1 score: 0.32705980761187786\n",
      "threshold:0.02 precision: 0.1955 recall: 1.0 f1 score: 0.32705980761187786\n",
      "threshold:0.04 precision: 0.1955 recall: 1.0 f1 score: 0.32705980761187786\n",
      "threshold:0.06 precision: 0.19677906391545041 recall: 1.0 f1 score: 0.328847771236333\n",
      "threshold:0.08 precision: 0.20591341077085534 recall: 0.9974424552429667 f1 score: 0.34135667396061264\n",
      "threshold:0.1 precision: 0.21797752808988763 recall: 0.9923273657289002 f1 score: 0.3574389682174113\n",
      "threshold:0.12 precision: 0.23049434187016082 recall: 0.989769820971867 f1 score: 0.37391304347826093\n",
      "threshold:0.14 precision: 0.24334600760456274 recall: 0.9820971867007673 f1 score: 0.39004570848146264\n",
      "threshold:0.16 precision: 0.25483655770513675 recall: 0.9769820971867008 f1 score: 0.4042328042328042\n",
      "threshold:0.18 precision: 0.2647887323943662 recall: 0.9616368286445013 f1 score: 0.4152401987852015\n",
      "threshold:0.2 precision: 0.27540500736377027 recall: 0.9565217391304348 f1 score: 0.4276729559748428\n",
      "threshold:0.22 precision: 0.28924980665119876 recall: 0.9565217391304348 f1 score: 0.44418052256532065\n",
      "threshold:0.24 precision: 0.302248126561199 recall: 0.928388746803069 f1 score: 0.45603015075376885\n",
      "threshold:0.26 precision: 0.3125548726953468 recall: 0.9104859335038363 f1 score: 0.465359477124183\n",
      "threshold:0.28 precision: 0.3292797006548176 recall: 0.9002557544757033 f1 score: 0.4821917808219178\n",
      "threshold:0.3 precision: 0.3465045592705167 recall: 0.8746803069053708 f1 score: 0.49637155297532654\n",
      "threshold:0.32 precision: 0.3588621444201313 recall: 0.8388746803069054 f1 score: 0.5026819923371647\n",
      "threshold:0.34 precision: 0.3778307508939213 recall: 0.8107416879795396 f1 score: 0.5154471544715447\n",
      "threshold:0.36 precision: 0.4 recall: 0.7979539641943734 f1 score: 0.5328778821520068\n",
      "threshold:0.38 precision: 0.4092140921409214 recall: 0.7723785166240409 f1 score: 0.5349867139061116\n",
      "threshold:0.4 precision: 0.42714285714285716 recall: 0.7647058823529411 f1 score: 0.5481209899175069\n",
      "threshold:0.42 precision: 0.44157814871016693 recall: 0.7442455242966752 f1 score: 0.5542857142857143\n",
      "threshold:0.44 precision: 0.4567307692307692 recall: 0.7289002557544757 f1 score: 0.5615763546798029\n",
      "threshold:0.46 precision: 0.4782608695652174 recall: 0.7033248081841432 f1 score: 0.5693581780538302\n",
      "threshold:0.48 precision: 0.4981549815498155 recall: 0.690537084398977 f1 score: 0.5787781350482315\n",
      "threshold:0.5 precision: 0.5245579567779961 recall: 0.6828644501278772 f1 score: 0.5933333333333334\n",
      "threshold:0.52 precision: 0.5381443298969072 recall: 0.6675191815856778 f1 score: 0.595890410958904\n",
      "threshold:0.54 precision: 0.5464601769911505 recall: 0.6317135549872123 f1 score: 0.5860023724792408\n",
      "threshold:0.56 precision: 0.569047619047619 recall: 0.6112531969309463 f1 score: 0.5893958076448829\n",
      "threshold:0.58 precision: 0.5906735751295337 recall: 0.5831202046035806 f1 score: 0.5868725868725868\n",
      "best threshold:0.52 best score:0.595890410958904\n"
     ]
    }
   ],
   "source": [
    "best_threshold = None\n",
    "best_score = 0\n",
    "for threshold in np.arange(0,0.6,0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold \n",
    "    precision = precision_score(target_valid,predicted_valid)\n",
    "    recall = recall_score(target_valid,predicted_valid)\n",
    "    f1 = f1_score(target_valid,predicted_valid)\n",
    "    print(f'threshold:{threshold} precision: {precision} recall: {recall} f1 score: {f1}')\n",
    "    if f1 > best_score:\n",
    "        best_score = f1\n",
    "        best_threshold = threshold\n",
    "print(f'best threshold:{best_threshold} best score:{best_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a slight increase in our f1 score by raising the threshold to 0.52."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Wow! Nice approach.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 / Auc-Roc Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8495411837824005"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_roc = roc_auc_score(target_valid,probabilities_one_valid)\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While not a perfect 1.0 score, this model performs much better than a model that guesses randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_valid,probabilities_one_valid)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot([0,1],[0,1],linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6405090137857901"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba = boost_model.predict_proba(encode_features_test)\n",
    "predicted_test = (predicted_proba[:,1] >= best_threshold).astype('int')\n",
    "f1 = f1_score(target_test,predicted_test)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6390899689762151"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test = boost_model.predict(encode_features_test)\n",
    "f1 = f1_score(target_test,predicted_test)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an f1 test score well over our threshold of 0.59 with and without adjusting the threshold to 0.52."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "We got F1 > 0.59! Well done!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "- Of the 4 models tested (logistic regression, decision trees, random forest, gradient boost) the Gradient Boosting Classifier performed the best with a 0.63 f1 score on the test dataset.\n",
    "- To overcome the class imbalance for the target (Exited), I downsampled the more prevalent class (0). \n",
    "- To optimize the model, I adjusted the hyperparameters for the number of estimators (n_estimators) and the maximum tree depth (max_depth)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Good final conclusion.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Overall reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "James, thank you for sending your project. You've done a really good job on it!\n",
    "    \n",
    "Especially impressed:\n",
    "\n",
    "- high code level\n",
    "\n",
    "- good project structure\n",
    "    \n",
    "- step with threshold adjustment\n",
    "    \n",
    "I'm glad to say that your project has been accepted. Keep up the good work, and good luck on the next sprint!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
